{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1 - Imports and defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import meshplot as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyFM.functional import FunctionalMapping\n",
    "from project.evaluate import EvaluateModel # evaluation class\n",
    "from pyFM.functional import FunctionalMapping # functional mapping class\n",
    "from project.cfunctional import CoupledFunctionalMapping # coupled functional mapping class\n",
    "from project.datasets import ShrecPartialDataset as SPD # Shrec dataset class\n",
    "from project.datasets import FaustRep as FR # Faust dataset class\n",
    "from project.datasets import Tosca as T # Tosca dataset class\n",
    "\n",
    "def plot_mesh(myMesh,cmap=None):\n",
    "    mp.plot(myMesh.vertlist, myMesh.facelist,c=cmap)\n",
    "    \n",
    "def double_plot(myMesh1,myMesh2,cmap1=None,cmap2=None):\n",
    "    d = mp.subplot(myMesh1.vertlist, myMesh1.facelist, c=cmap1, s=[2, 2, 0])\n",
    "    mp.subplot(myMesh2.vertlist, myMesh2.facelist, c=cmap2, s=[2, 2, 1], data=d)\n",
    "\n",
    "def visu(vertices):\n",
    "    min_coord,max_coord = np.min(vertices,axis=0,keepdims=True),np.max(vertices,axis=0,keepdims=True)\n",
    "    cmap = (vertices-min_coord)/(max_coord-min_coord)\n",
    "    return cmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Evaluating Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of paths, **adjust to your local paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_cp2p = \"../../data/cp2p_dev\"\n",
    "data_path_faust = \"../../data/MPI-FAUST_dev\"\n",
    "data_path_tosca = \"../../data/SGP_dataset_off\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional mapping on FAUST representation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- preprocess_params arguments are given to model.preprocess()\n",
    "- fit_params arguments are given to model.fit()\n",
    "- data_params arguments are given to the dataclass initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading mesh tr_reg_000\n",
      "loading mesh tr_reg_001\n",
      "loading mesh tr_reg_002\n",
      "loading mesh tr_reg_003\n",
      "loading mesh tr_reg_004\n",
      "loading mesh tr_reg_005\n",
      "loading mesh tr_reg_006\n",
      "Initialization done!\n"
     ]
    }
   ],
   "source": [
    "evaluation = EvaluateModel(\n",
    "    FunctionalMapping, FR, data_path_faust, refine=False, \n",
    "    preprocess_params={\n",
    "        'n_ev': (35,35),  # Number of eigenvalues on source and Target\n",
    "        # 'landmarks': np.loadtxt('data/landmarks.txt',dtype=int)[:5],  # loading 5 landmarks\n",
    "        'subsample_step': 5,  # In order not to use too many descriptors\n",
    "        'descr_type': 'WKS',  # WKS or HKS\n",
    "    },\n",
    "    fit_params={\n",
    "        'w_descr': 1e0,\n",
    "        'w_lap': 1e-2,\n",
    "        'w_dcomm': 1e-1,\n",
    "        'w_orient': 0\n",
    "    },\n",
    "    # data_params={\n",
    "    #     'name': 'cuts',\n",
    "    #     'selected': True\n",
    "    # },\n",
    "    verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call eval() function to evaluate the given dataset on the given model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [14:55<00:00, 42.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy results\n",
      "\tBasic FM : 85.84\n",
      "\n",
      "Standard deviation of accuracy results\n",
      "\tBasic FM : 95.72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coupled Functional Mapping on Tosca Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading mesh cat0_partial1\n",
      "loading mesh cat0_partial3\n",
      "loading mesh david0_partial1\n",
      "loading mesh david0_partial3\n",
      "loading mesh david1_partial4\n",
      "loading mesh dog0_partial5\n",
      "loading mesh dog2_partial2\n",
      "loading mesh dog3_partial2\n",
      "loading mesh victoria0_partial4\n",
      "loading mesh victoria1_partial6\n",
      "loading mesh cat0\n",
      "loading mesh cat1\n",
      "loading mesh cat10\n",
      "loading mesh cat2\n",
      "loading mesh cat3\n",
      "loading mesh cat4\n",
      "loading mesh cat5\n",
      "loading mesh cat6\n",
      "loading mesh cat7\n",
      "loading mesh cat8\n",
      "loading mesh cat9\n",
      "loading mesh centaur0\n",
      "loading mesh centaur1\n",
      "loading mesh centaur2\n",
      "loading mesh centaur3\n",
      "loading mesh centaur4\n",
      "loading mesh centaur5\n",
      "loading mesh david0\n",
      "loading mesh david1\n",
      "loading mesh david10\n",
      "loading mesh david11\n",
      "loading mesh david12\n",
      "loading mesh david13\n",
      "loading mesh david6\n",
      "loading mesh dog0\n",
      "loading mesh dog1\n",
      "loading mesh dog10\n",
      "loading mesh dog2\n",
      "loading mesh dog3\n",
      "loading mesh dog5\n",
      "loading mesh dog6\n",
      "loading mesh dog7\n",
      "loading mesh dog8\n",
      "loading mesh horse0\n",
      "loading mesh horse10\n",
      "loading mesh horse14\n",
      "loading mesh horse15\n",
      "loading mesh horse17\n",
      "loading mesh horse5\n",
      "loading mesh horse6\n",
      "loading mesh horse7\n",
      "loading mesh michael0\n",
      "loading mesh michael1\n",
      "loading mesh michael10\n",
      "loading mesh michael11\n",
      "loading mesh michael12\n",
      "loading mesh michael13\n",
      "loading mesh michael14\n",
      "loading mesh michael15\n",
      "loading mesh michael16\n",
      "loading mesh michael17\n",
      "loading mesh michael18\n",
      "loading mesh michael19\n",
      "loading mesh michael2\n",
      "loading mesh michael3\n",
      "loading mesh michael4\n",
      "loading mesh michael5\n",
      "loading mesh michael6\n",
      "loading mesh michael7\n",
      "loading mesh michael8\n",
      "loading mesh michael9\n",
      "loading mesh victoria0\n",
      "loading mesh victoria1\n",
      "loading mesh victoria10\n",
      "loading mesh victoria12\n",
      "loading mesh victoria17\n",
      "loading mesh victoria2\n",
      "loading mesh victoria21\n",
      "loading mesh victoria23\n",
      "loading mesh victoria24\n",
      "loading mesh victoria25\n",
      "loading mesh victoria4\n",
      "loading mesh victoria7\n",
      "loading mesh wolf0\n",
      "loading mesh wolf1\n",
      "loading mesh wolf2\n",
      "Initialization done!\n"
     ]
    }
   ],
   "source": [
    "evaluation_c = EvaluateModel(\n",
    "    CoupledFunctionalMapping, T, data_path_tosca, refine=False, \n",
    "    preprocess_params={\n",
    "        'n_ev': (35,35),  # Number of eigenvalues on source and Target\n",
    "        # 'landmarks': np.loadtxt('data/landmarks.txt',dtype=int)[:5],  # loading 5 landmarks\n",
    "        'subsample_step': 5,  # In order not to use too many descriptors\n",
    "        'descr_type': 'WKS',  # WKS or HKS\n",
    "    },\n",
    "    fit_params={\n",
    "        'mu_coup': 1e-1,\n",
    "        'mu_mask': 1e-2,\n",
    "        'mu_des': 1e-1,\n",
    "    },\n",
    "    data_params={\n",
    "        'name': 'cuts',\n",
    "        'selected': True,\n",
    "        'use_adj': True\n",
    "    },\n",
    "    verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nit:3926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 1/10 [01:38<14:43, 98.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nit:4217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 2/10 [03:14<12:55, 96.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nit:4815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▉                                                          | 3/10 [04:51<11:18, 96.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nit:5514\n"
     ]
    }
   ],
   "source": [
    "evaluation_c.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional Mapping on Tosca Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_fm = EvaluateModel(\n",
    "    FunctionalMapping, T, data_path_tosca, refine=False, \n",
    "    preprocess_params={\n",
    "        'n_ev': (35,35),  # Number of eigenvalues on source and Target\n",
    "        # 'landmarks': np.loadtxt('data/landmarks.txt',dtype=int)[:5],  # loading 5 landmarks\n",
    "        'subsample_step': 5,  # In order not to use too many descriptors\n",
    "        'descr_type': 'WKS',  # WKS or HKS\n",
    "    },\n",
    "    fit_params={\n",
    "        'w_descr': 1e0,\n",
    "        'w_lap': 1e-2,\n",
    "        'w_dcomm': 1e-1,\n",
    "        'w_orient': 0\n",
    "    },\n",
    "    data_params={\n",
    "        'name': 'cuts',\n",
    "        'selected': True,\n",
    "        'use_adj': True\n",
    "    },\n",
    "    verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_fm.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**adjust paths to your local paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_res(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return [float(x) for x in f.read().split(\", \")]\n",
    "\n",
    "\n",
    "FM_res = load_res(f'data/eval/distances_FunctionalMapping_Tosca.txt')\n",
    "CFM_res = load_res(f'data/eval/distances_CoupledFunctionalMapping_Tosca.txt')\n",
    "\n",
    "# FM_res = load_res(f'data/eval/distances_FunctionalMapping_FaustRep.txt')\n",
    "# CFM_res = load_res(f'data/eval/distances_CoupledFunctionalMapping_FaustRep.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_res(x, y):\n",
    "    x = np.sort(x)\n",
    "    f_x = np.array(range(len(x)))/float(len(x))\n",
    "    y = np.sort(y)\n",
    "    f_y = np.array(range(len(y)))/float(len(y))\n",
    "\n",
    "    plt.plot(x, f_x, label='FM')\n",
    "    plt.plot(y, f_y, label='CFM')\n",
    "#     plt.title('Geod. distance distribution (FAUST representations)')\n",
    "    plt.title('Geod. distance distribution (Tosca)')\n",
    "    plt.xlabel('Geodesic error')\n",
    "    plt.ylabel('% Correspondences')\n",
    "    plt.xlim([0.0, 1.5])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.legend()\n",
    "\n",
    "#     plt.savefig(f\"data/eval/FM_v_CFM_Faust.png\", bbox_inches='tight', dpi=200)\n",
    "    plt.savefig(f\"data/eval/FM_v_CFM_Tosca.png\", bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res(FM_res, CFM_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e956ee7660bdd64c6d0f8ca0a4d1ec0d49840f6dce9aa7b6de62a1b26319698c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
