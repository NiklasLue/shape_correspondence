{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxPKSPp3QEhV"
   },
   "source": [
    "# Only for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57182,
     "status": "ok",
     "timestamp": 1658469249016,
     "user": {
      "displayName": "Pietro Massetani",
      "userId": "07865819923768454955"
     },
     "user_tz": -120
    },
    "id": "dcwEbH0WjdhL",
    "outputId": "a9df8102-2705-4ffc-b840-fc2fb4e37c79"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1658469249018,
     "user": {
      "displayName": "Pietro Massetani",
      "userId": "07865819923768454955"
     },
     "user_tz": -120
    },
    "id": "knfvtVWwjqCz",
    "outputId": "8d74809e-da01-4e8d-f3d3-ec0ee5594b6f"
   },
   "outputs": [],
   "source": [
    "# %cd drive/MyDrive/pyFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NGQOOGg3t8gU",
    "outputId": "2ec3399a-39cd-4c28-b993-7742962a8bbe"
   },
   "outputs": [],
   "source": [
    "# !pip install potpourri3d robust_laplacian open3d trimesh tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before this, run split_data_DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ibY8LIGRQEhd"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KkPsFSk6QEhd"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9SegfV7QEhe"
   },
   "source": [
    "# Train and evaluate dpfm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "yj5y_wU3jZh6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from dann.main import main\n",
    "from dann.test import test_target, test_source\n",
    "from project.datasets import Tosca\n",
    "from project.train_dpfm import train_net\n",
    "from project.eval_dpfm import eval_net\n",
    "from dann.main_test import main_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "h2S8whHvjZiB"
   },
   "outputs": [],
   "source": [
    "cfg = yaml.safe_load(open(f\"dann/config/tosca_cuts_da.yaml\", \"r\"))\n",
    "source_domain_path = '../data/Tosca_DA/source/train'\n",
    "target_domain_path = '../data/Tosca_DA/target/train'\n",
    "source_test_path = '../data/Tosca_DA/source/test'\n",
    "target_test_path = '../data/Tosca_DA/target/test'\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "3MINkj0ROGV_"
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "# !rm -rf ./runs/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "4Afoh7qGO-AX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 13824), started 2 days, 0:08:24 ago. (Use '!kill 13824' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8f7324be74177a37\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8f7324be74177a37\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir runs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Z6Eq_zscjZi8",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using dataset cache path: ../data/Tosca_DA/source/train\\cache_cuts_train.pt\n",
      "  --> loading dataset from cache\n",
      "using dataset cache path: ../data/Tosca_DA/target/train\\cache_cuts_train.pt\n",
      "  --> loading dataset from cache\n",
      "Source-only training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [01:50<00:00, 110.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#epoch:1, #iteration:89, train_loss:170.34587624367703, val_loss:8.818007510641348\n",
      "DANN training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [02:35<00:00, 155.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#epoch:1, train_loss:120.51419251688411, val_loss_src:8.680221764937691, val_loss_tgt:31.911810418833856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main(source_domain_path,target_domain_path,cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VIRQn1tBQEhj"
   },
   "source": [
    "**Note**: Change model path to your respective path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5owMbZ3QEhj"
   },
   "source": [
    "### FM evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ykckuH4pjZi-",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using dataset cache path: ../data/Tosca_DA/source/test\\cache_cuts_train.pt\n",
      "  --> loading dataset from cache\n",
      "using dataset cache path: ../data/Tosca_DA/target/test\\cache_cuts_train.pt\n",
      "  --> loading dataset from cache\n",
      "Starting evaluation...\n",
      "Using device cuda:0\n",
      "Loading model...\n",
      "Starting inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/44 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "pred_p2p_list_tgt, pred_p2p_list_src = main_test(source_test_path, target_test_path, 'dann/data/dann_training.pth', cfg, 'test_tosca.pt', n_samples=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "-Z9Akq8EQEhk"
   },
   "outputs": [],
   "source": [
    "#p2p_fm, distances_fm = eval_net(cfg, \"project/data/saved_models_cuts_3/ep_49.pth\", \"data/eval/test_tosca.pt\", return_pred_p2p=True, return_dist=True, mode=\"FM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37w1Eg2nQEhk"
   },
   "source": [
    "### CFM evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "d2NH-qtUQEhl"
   },
   "outputs": [],
   "source": [
    "#p2p_cfm, distances_cfm = eval_net(cfg,\"project/data/saved_models_cuts_3/ep_49.pth\", \"data/eval/test_tosca.pt\", return_pred_p2p=True, return_dist=True, mode=\"CFM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWl7R07sQEhl"
   },
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "166qlnsMGIFt"
   },
   "source": [
    "# Notes\n",
    "- Trained on 26 shapes, tested on 6 shapes (80/20 train/test split)\n",
    "- Training process seems to work well, can't tell if it's overfitting due to lack of validation implementation\n",
    "- Errors:\n",
    "  - WKS: 5.99\n",
    "  - DPFM trained on 26 shapes: 0.66\n",
    "  - DPFM trained on 60% of TOSCA: 0.50\n",
    "- Compared to FM with hand-crafted descriptors (WKS): 5.99 <-> 0.66 (mean normalized geodesic error)\n",
    "- Improvements:\n",
    "  - validation set implementation\n",
    "  - tensorboard visualization\n",
    "  - lr scheduler from pytorch\n",
    "  - inference is slow, mostly done on CPU, transfer to GPU\n",
    "- Next steps:\n",
    "  - double check all dataloaders & FM to p2p conversions\n",
    "  - training on whole partial-to-full dataset (TOSCA), or mix full-to-full & partial-to-full, e.g. warm start with model pre-trained on an easier problem, i.e. full-to-full\n",
    "  - combine model w/ coupled FM\n",
    "  - implement gradient clipping\n",
    "  - apply trained descriptors to CFM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lk3aEhl6GACe"
   },
   "source": [
    "# Change log\n",
    "\n",
    "- Remove data augmentation in validation step\n",
    "- LR scheduler decaying too fast, use reduceLROnPlateau() with average validation loss\n",
    "- use average of train and val loss for evaluation\n",
    "- implement tensorboard logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNKDrvzMOxGi"
   },
   "source": [
    "# Done\n",
    "- trained model for 39 epochs on all shapes, good training error, val error is very high, might be a bug"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "da_example_notebook.ipynb",
   "version": ""
  },
  "interpreter": {
   "hash": "e956ee7660bdd64c6d0f8ca0a4d1ec0d49840f6dce9aa7b6de62a1b26319698c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
